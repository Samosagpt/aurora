#!/usr/bin/env python3
"""
GPU Detection and CUDA Compatibility Checker for Samosa GPT
"""

import subprocess
import sys
import platform

def check_nvidia_gpu():
    """Check for NVIDIA GPU using multiple methods."""
    try:
        # Method 1: nvidia-smi
        result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            gpus = [gpu.strip() for gpu in result.stdout.strip().split('\n') if gpu.strip()]
            return gpus
    except FileNotFoundError:
        pass
    
    # Method 2: wmic (Windows)
    if platform.system() == "Windows":
        try:
            result = subprocess.run(['wmic', 'path', 'win32_VideoController', 'get', 'name'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                nvidia_gpus = [line.strip() for line in lines 
                             if 'nvidia' in line.lower() and line.strip() and 'name' not in line.lower()]
                return nvidia_gpus
        except Exception:
            pass
    
    return []

def check_amd_gpu():
    """Check for AMD GPU."""
    if platform.system() == "Windows":
        try:
            result = subprocess.run(['wmic', 'path', 'win32_VideoController', 'get', 'name'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                amd_gpus = [line.strip() for line in lines 
                          if ('amd' in line.lower() or 'radeon' in line.lower()) 
                          and line.strip() and 'name' not in line.lower()]
                return amd_gpus
        except Exception:
            pass
    return []

def check_pytorch_cuda():
    """Check if PyTorch is installed and CUDA-enabled."""
    try:
        import torch
        return {
            'installed': True,
            'version': torch.__version__,
            'cuda_available': torch.cuda.is_available(),
            'cuda_version': torch.version.cuda if hasattr(torch.version, 'cuda') else None,
            'device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,
            'devices': [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())] 
                      if torch.cuda.is_available() else []
        }
    except ImportError:
        return {'installed': False}

def get_cuda_version():
    """Get CUDA toolkit version if available."""
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            for line in result.stdout.split('\n'):
                if 'release' in line.lower():
                    return line.strip()
    except FileNotFoundError:
        pass
    return None

def main():
    print("=== GPU and CUDA Compatibility Check ===\n")
    
    # Check for NVIDIA GPUs
    nvidia_gpus = check_nvidia_gpu()
    if nvidia_gpus:
        print("NVIDIA GPUs detected:")
        for gpu in nvidia_gpus:
            print(f"  - {gpu}")
    else:
        print("No NVIDIA GPUs detected")
    
    # Check for AMD GPUs
    amd_gpus = check_amd_gpu()
    if amd_gpus:
        print("\nAMD GPUs detected:")
        for gpu in amd_gpus:
            print(f"  - {gpu}")
    
    if not nvidia_gpus and not amd_gpus:
        print("No dedicated GPUs detected - will use CPU-only PyTorch")
    
    # Check CUDA toolkit
    cuda_version = get_cuda_version()
    if cuda_version:
        print(f"\nCUDA Toolkit: {cuda_version}")
    elif nvidia_gpus:
        print("\nCUDA Toolkit: Not found (install from https://developer.nvidia.com/cuda-downloads)")
    
    # Check PyTorch
    pytorch_info = check_pytorch_cuda()
    if pytorch_info['installed']:
        print(f"\nPyTorch Status:")
        print(f"  Version: {pytorch_info['version']}")
        print(f"  CUDA Available: {pytorch_info['cuda_available']}")
        if pytorch_info['cuda_available']:
            print(f"  CUDA Version: {pytorch_info.get('cuda_version', 'Unknown')}")
            print(f"  GPU Devices: {pytorch_info['device_count']}")
            for i, device in enumerate(pytorch_info['devices']):
                print(f"    Device {i}: {device}")
    else:
        print("\nPyTorch: Not installed")
    
    # Recommendations
    print("\n=== Recommendations ===")
    if nvidia_gpus and not pytorch_info.get('cuda_available', False):
        if not cuda_version:
            print("1. Install CUDA Toolkit from https://developer.nvidia.com/cuda-downloads")
            print("2. Reinstall PyTorch with CUDA support")
        else:
            print("Install PyTorch with CUDA support:")
            print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    elif amd_gpus:
        print("Install PyTorch with ROCm support:")
        print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6")
    elif not nvidia_gpus and not amd_gpus:
        print("Install CPU-only PyTorch:")
        print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu")
    elif pytorch_info.get('cuda_available', False):
        print("âœ“ PyTorch with CUDA support is properly configured!")

if __name__ == "__main__":
    main()
